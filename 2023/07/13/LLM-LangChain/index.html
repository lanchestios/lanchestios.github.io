<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 6.2.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/all.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"example.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":false,"show_result":false,"style":null},"back2top":{"enable":true,"sidebar":false,"scrollpercent":false},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":-1,"unescape":true,"preload":true},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="LangChain 是一个用于开发由语言模型支持的应用程序的框架。它支持以下应用程序：  Data-aware：将语言模型连接到其他数据源 Agentic：允许语言模型与其环境交互  LangChain 的主要价值有：  Components：用于处理语言模型的抽象，以及每个抽象的实现集合。 Off-the-shelf chains：用于完成特定更高级别任务的组件的结构化组装">
<meta property="og:type" content="article">
<meta property="og:title" content="LLM LangChain">
<meta property="og:url" content="http://example.com/2023/07/13/LLM-LangChain/index.html">
<meta property="og:site_name" content="Lanchester Blog">
<meta property="og:description" content="LangChain 是一个用于开发由语言模型支持的应用程序的框架。它支持以下应用程序：  Data-aware：将语言模型连接到其他数据源 Agentic：允许语言模型与其环境交互  LangChain 的主要价值有：  Components：用于处理语言模型的抽象，以及每个抽象的实现集合。 Off-the-shelf chains：用于完成特定更高级别任务的组件的结构化组装">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/images/LLM/模型IO.jpg">
<meta property="og:image" content="http://example.com/images/LLM/数据连接.webp">
<meta property="og:image" content="http://example.com/images/LLM/文档链stuff.jpg">
<meta property="og:image" content="http://example.com/images/LLM/文档链refine.jpg">
<meta property="og:image" content="http://example.com/images/LLM/文档链mapreduce.jpeg">
<meta property="og:image" content="http://example.com/images/LLM/文档链maprerank.jpeg">
<meta property="article:published_time" content="2023-07-13T11:46:03.000Z">
<meta property="article:modified_time" content="2023-08-07T06:52:51.944Z">
<meta property="article:author" content="Wang Zihao">
<meta property="article:tag" content="LLM">
<meta property="article:tag" content="LangChain">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/images/LLM/模型IO.jpg">

<link rel="canonical" href="http://example.com/2023/07/13/LLM-LangChain/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'en'
  };
</script>

  <title>LLM LangChain | Lanchester Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">Lanchester Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">Leave a leaf</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="main-menu menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a>

  </li>
        <li class="menu-item menu-item-about">

    <a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>About</a>

  </li>
        <li class="menu-item menu-item-tags">

    <a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a>

  </li>
        <li class="menu-item menu-item-categories">

    <a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>Categories</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>Search
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="Searching..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="http://example.com/2023/07/13/LLM-LangChain/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="Wang Zihao">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Lanchester Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          LLM LangChain
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2023-07-13 19:46:03" itemprop="dateCreated datePublished" datetime="2023-07-13T19:46:03+08:00">2023-07-13</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2023-08-07 14:52:51" itemprop="dateModified" datetime="2023-08-07T14:52:51+08:00">2023-08-07</time>
              </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-folder"></i>
              </span>
              <span class="post-meta-item-text">In</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/LLM/" itemprop="url" rel="index"><span itemprop="name">LLM</span></a>
                </span>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <p>LangChain 是一个用于开发由语言模型支持的应用程序的框架。它支持以下应用程序：</p>
<ul>
<li><strong>Data-aware</strong>：将语言模型连接到其他数据源</li>
<li><strong>Agentic</strong>：允许语言模型与其环境交互</li>
</ul>
<p>LangChain 的主要价值有：</p>
<ol>
<li><strong>Components</strong>：用于处理语言模型的抽象，以及每个抽象的实现集合。</li>
<li><strong>Off-the-shelf chains</strong>：用于完成特定更高级别任务的组件的结构化组装</li>
</ol>
<span id="more"></span>
<h1 id="模型IO"><a href="#模型IO" class="headerlink" title="模型IO"></a>模型IO</h1><p>任何语言模型应用的核心元素是模型。LangChain 为您提供了连接任何语言模型的构建模块。</p>
<ul>
<li>提示 Prompt： 模板化、动态选择和管理模型输入</li>
<li>语言模型 Language Models： 通过通用接口调用语言模型</li>
<li>输出分析器 Output Parser： 从模型输出中提取信息</li>
</ul>
<p><img src="/images/LLM/模型IO.jpg" alt=""></p>
<h2 id="提示-Prompts"><a href="#提示-Prompts" class="headerlink" title="提示 Prompts"></a>提示 Prompts</h2><p>编程模型是通过提示 Prompt。提示 Prompt 指的是模型的输入，输入通常由多个部分构成。</p>
<ul>
<li>提示模版 Prompt Templates：参数化模型输入</li>
<li>示例选择器 Example Selectors：动态选择要包含在提示中的示例</li>
</ul>
<p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/">TODO</a></p>
<h3 id="Prompt-Templates"><a href="#Prompt-Templates" class="headerlink" title="Prompt Templates"></a>Prompt Templates</h3><p>可以通过自动/手动两种方式使用提示模版：</p>
<p><strong>1. 自动录入参数</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate

prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
你是一位兽医，帮助用户处理他们的宠物.

&#123;context&#125;

Question: &#123;question&#125;
Answer is:
"""</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>prompt_template<span class="token punctuation">)</span>
prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>context<span class="token operator">=</span><span class="token string">"一只鸡能活100年。"</span><span class="token punctuation">,</span> question<span class="token operator">=</span><span class="token string">"一只鸡能存活多久？"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>2. 手动指定参数</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> PromptTemplate

prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""
你是一位兽医，帮助用户处理他们的宠物.

&#123;context&#125;

Question: &#123;question&#125;
Answer is:
"""</span>
prompt_template <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">,</span> <span class="token string">"question"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> template<span class="token operator">=</span>prompt_template<span class="token punctuation">)</span>
prompt <span class="token operator">=</span> prompt_template<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>context<span class="token operator">=</span><span class="token string">"一只鸡能活100年。"</span><span class="token punctuation">,</span> question<span class="token operator">=</span><span class="token string">"一只鸡能存活多久？"</span><span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>prompt<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Chat-Prompt-Template"><a href="#Chat-Prompt-Template" class="headerlink" title="Chat Prompt Template"></a>Chat Prompt Template</h3><p>聊天模型可以区分不同角色，对聊天的相关信息进行输入。例如，在 OpenAI <a target="_blank" rel="noopener" href="https://platform.openai.com/docs/guides/chat/introduction">Chat Completion API</a> 中，聊天消息可以与 AI、人类或系统角色相关联。该模型应该更紧密地遵循系统聊天消息的指令。</p>
<p>LangChain 提供了多种提示模板，可以轻松构建和使用提示。我们鼓励您使用这些聊天相关的提示模板，而不是<code>PromptTemplate</code>在查询聊天模型时使用，以充分利用底层聊天模型的潜力。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> <span class="token punctuation">(</span>
    ChatPromptTemplate<span class="token punctuation">,</span>
    PromptTemplate<span class="token punctuation">,</span>
    SystemMessagePromptTemplate<span class="token punctuation">,</span>
    AIMessagePromptTemplate<span class="token punctuation">,</span>
    HumanMessagePromptTemplate<span class="token punctuation">,</span>
<span class="token punctuation">)</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage
<span class="token punctuation">)</span>

system_template<span class="token operator">=</span> <span class="token string">"You are a helpful assistant that translates &#123;input_language&#125; to &#123;output_language&#125;."</span>
system_message_prompt <span class="token operator">=</span> SystemMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>system_template<span class="token punctuation">)</span>
human_template<span class="token operator">=</span><span class="token string">"&#123;text&#125;"</span>
human_message_prompt <span class="token operator">=</span> HumanMessagePromptTemplate<span class="token punctuation">.</span>from_template<span class="token punctuation">(</span>human_template<span class="token punctuation">)</span>

chat_prompt <span class="token operator">=</span> ChatPromptTemplate<span class="token punctuation">.</span>from_messages<span class="token punctuation">(</span><span class="token punctuation">[</span>system_message_prompt<span class="token punctuation">,</span> human_message_prompt<span class="token punctuation">]</span><span class="token punctuation">)</span>

chat_prompt<span class="token punctuation">.</span>format_prompt<span class="token punctuation">(</span>input_language<span class="token operator">=</span><span class="token string">"English"</span><span class="token punctuation">,</span> output_language<span class="token operator">=</span><span class="token string">"French"</span><span class="token punctuation">,</span> text<span class="token operator">=</span><span class="token string">"I love programming."</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to_messages<span class="token punctuation">(</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="语言模型-Language-Models"><a href="#语言模型-Language-Models" class="headerlink" title="语言模型 Language Models"></a>语言模型 Language Models</h2><p>LangChain 提供了两种类型模型的抽象和实现。</p>
<ol>
<li>LLMS：输入输出都为文本的语言模型</li>
<li>Chat Models：输入输出都为聊天信息 Chat Message 的语言模型</li>
</ol>
<blockquote>
<p><strong>LLMS 和 Chat Models 的区别</strong></p>
<p>LLMs（Language Model）和 Chat Models（聊天模型）在细微但重要的方面有所不同。LangChain 中的 LLMs 指的是纯文本补全模型。它们包装的 API 接受一个字符串提示作为输入，并输出一个字符串补全结果。OpenAI 的 GPT-3 就是一个 LLM 实现。Chat Models 通常基于 LLMs，但专门用于进行对话，并且它们的提供者 API 公开了与纯文本补全模型不同的接口。它们接受的不是单个字符串，而是一个包含对话消息的列表作为输入。通常，这些消息会标记说话者（通常是”System”、”AI”和”Human”之一）。然后它们会返回一个（”AI”）聊天消息作为输出。GPT-4 和 Anthropic 的 Claude 都是作为 Chat Models 实现的。</p>
<p>为了能够交换 LLMs 和 Chat Models，两者都实现了 Base Language Model 接口。该接口提供了共同的方法”predict”，它接受一个字符串并返回一个字符串，以及”predict messages”方法，它接受消息并返回一个消息。如果您正在使用特定的模型，建议使用该模型类的特定方法（即 LLMs 使用 “predict”，Chat Models 使用 “predict messages”），但如果您正在创建一个可以与不同类型的模型一起使用的应用程序，共享的接口可能会很有帮助。</p>
</blockquote>
<h3 id="LLMS"><a href="#LLMS" class="headerlink" title="LLMS"></a>LLMS</h3><p>Large Language Models (LLMs) 是 LangChain 的核心组件。LangChain 并没有自己的 LLMs 实现，而是为 LLMs 们提供了标准的接口。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI

<span class="token comment"># openai_api_key 也可以放到环境变量里自动加载</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span>openai_api_key<span class="token operator">=</span><span class="token string">"..."</span><span class="token punctuation">)</span>

<span class="token comment"># 单次调用</span>
llm<span class="token punctuation">(</span><span class="token string">"Tell me a joke"</span><span class="token punctuation">)</span>
<span class="token comment"># 批次调用</span>
llm<span class="token punctuation">.</span>generate<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">"Tell me a joke"</span><span class="token punctuation">,</span> <span class="token string">"Tell me a poem"</span><span class="token punctuation">]</span><span class="token operator">*</span><span class="token number">15</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Chat-Models"><a href="#Chat-Models" class="headerlink" title="Chat Models"></a>Chat Models</h3><p>Chat Model 是 Large Language Model 的变体。虽然聊天模型在底层使用语言模型，但它们的界面有点不同。它们不是公开“文本输入、文本输出”API，而是公开一个接口，其中“聊天消息”是输入和输出。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>
    AIMessage<span class="token punctuation">,</span>
    HumanMessage<span class="token punctuation">,</span>
    SystemMessage
<span class="token punctuation">)</span>

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># 单次调用</span>
chat<span class="token punctuation">(</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Translate this sentence from English to French: I love programming."</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token comment"># 批次调用</span>
batch_messages <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a helpful assistant that translates English to French."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I love programming."</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
    <span class="token punctuation">[</span>
        SystemMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"You are a helpful assistant that translates English to French."</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
        HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"I love artificial intelligence."</span><span class="token punctuation">)</span>
    <span class="token punctuation">]</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>
result <span class="token operator">=</span> chat<span class="token punctuation">.</span>generate<span class="token punctuation">(</span>batch_messages<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="Caching"><a href="#Caching" class="headerlink" title="Caching"></a>Caching</h4><p>LangChain 为 Chat Model 提供了一个可选的缓存层。它会缓存询问的问题以及 LLM 给出的回答，当再次访问时，回答缓存的内容。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">import</span> langchain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>cache <span class="token keyword">import</span> InMemoryCache

llm <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>
langchain<span class="token punctuation">.</span>llm_cache <span class="token operator">=</span> InMemoryCache<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token comment"># The first time, it is not yet in cache, so it should take longer</span>
llm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token string">"Tell me a joke"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">CPU times: user 35.9 ms, sys: 28.6 ms, total: 64.6 ms
Wall time: 4.83 s


"\n\nWhy couldn't the bicycle stand up by itself? It was...two tired!"<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># The second time it is, so it goes faster</span>
llm<span class="token punctuation">.</span>predict<span class="token punctuation">(</span><span class="token string">"Tell me a joke"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span></span></code></pre>
<pre class="line-numbers language-text" data-language="text"><code class="language-text">CPU times: user 238 µs, sys: 143 µs, total: 381 µs
Wall time: 1.76 ms


'\n\nWhy did the chicken cross the road?\n\nTo get to the other side.'<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>除了内存缓存，也提供了 SQLite 的方式</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># We can do the same thing with a SQLite cache</span>
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>cache <span class="token keyword">import</span> SQLiteCache
langchain<span class="token punctuation">.</span>llm_cache <span class="token operator">=</span> SQLiteCache<span class="token punctuation">(</span>database_path<span class="token operator">=</span><span class="token string">".langchain.db"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h4 id="Streaming"><a href="#Streaming" class="headerlink" title="Streaming"></a>Streaming</h4><p>有一些语言模型提供了流式响应能力，即无需等待完整响应返回即可接收到部分内容。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chat_models <span class="token keyword">import</span> ChatOpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>schema <span class="token keyword">import</span> <span class="token punctuation">(</span>
    HumanMessage<span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>callbacks<span class="token punctuation">.</span>streaming_stdout <span class="token keyword">import</span> StreamingStdOutCallbackHandler

chat <span class="token operator">=</span> ChatOpenAI<span class="token punctuation">(</span>streaming<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> callbacks<span class="token operator">=</span><span class="token punctuation">[</span>StreamingStdOutCallbackHandler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">,</span> temperature<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
resp <span class="token operator">=</span> chat<span class="token punctuation">(</span><span class="token punctuation">[</span>HumanMessage<span class="token punctuation">(</span>content<span class="token operator">=</span><span class="token string">"Write me a song about sparkling water."</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h2 id="输出分析器-Output-Parser"><a href="#输出分析器-Output-Parser" class="headerlink" title="输出分析器 Output Parser"></a>输出分析器 Output Parser</h2><p>Output Parser 可以帮助结构化 LLM 的输出。</p>
<p>LangChain 提供了多种实现，也支持自定义：</p>
<ol>
<li>List Parser</li>
<li>DateTime Parser</li>
<li>Enum Parser</li>
<li>Auto-fixing Parser</li>
<li>Pydantic（JSON）Parser</li>
<li>Retry Parser</li>
<li>Structured Output Parser</li>
</ol>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/model_io/output_parsers/">[LangChain] Models I/O - Output Parser</a></p>
<h1 id="数据连接-Data-Connection"><a href="#数据连接-Data-Connection" class="headerlink" title="数据连接 Data Connection"></a>数据连接 Data Connection</h1><p>许多 LLM 应用需要用户特定的数据，这些数据不属于模型的训练集。</p>
<p>LangChain 通过以下方式为你提供了加载、转换、存储和查询数据的构建模块：</p>
<ul>
<li>文档加载器：从许多不同的来源加载文档</li>
<li>文档转换器：分割文档，删除多余的文档等</li>
<li>文本嵌入模型：采取非结构化文本，并把它变成一个浮点数的列表 矢量存储：存储和搜索嵌入式数据</li>
<li>检索器：查询你的数据</li>
</ul>
<p><img src="/images/LLM/数据连接.webp" alt=""></p>
<p><strong>依赖包</strong></p>
<pre class="line-numbers language-bash" data-language="bash"><code class="language-bash">pip <span class="token function">install</span> langchain
pip <span class="token function">install</span> unstructured
pip <span class="token function">install</span> jq<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="文档加载器-Document-Loaders"><a href="#文档加载器-Document-Loaders" class="headerlink" title="文档加载器 Document Loaders"></a>文档加载器 Document Loaders</h2><p>将不同类型的文档格式转为统一的 Document 领域对象，并提供了多种实现。大致分为以下几类：</p>
<ol>
<li>文件加载器 File Loader</li>
<li>目录加载器 Directory</li>
<li>Web加载器 WebLoader</li>
</ol>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/data_connection/document_loaders/">[LangChain] Document Loader</a></p>
<h2 id="文档转换器-Document-Transformers"><a href="#文档转换器-Document-Transformers" class="headerlink" title="文档转换器 Document Transformers"></a>文档转换器 Document Transformers</h2><p>将通过 Document Loaders 加载的数据进行转换，变得适用于应用理解。</p>
<p>处理文档通常有下述步骤：</p>
<ol>
<li>将文本切分成小的、具有语义意义的块 chunks（通常是句子）</li>
<li>将小的 chunks 组合成一个符合模型通用输入的标准 chunks</li>
<li>将标准 chunks 进行部分重叠，以保留文本的上下文结构 </li>
</ol>
<p>实现上述逻辑的叫做文本切分器 Text Splitter，其通常以两个维度进行自定义：</p>
<ol>
<li>文本怎样切分</li>
<li>块大小如何测量</li>
</ol>
<p>文本切分器大致可以分为以下几类：</p>
<ol>
<li>字符切分器（仅按照字符进行分割）</li>
<li>代码切分器（允许通过不同的编程语法进行切分）</li>
<li>MarkDown 切分器（切分 MarkDown 文本）</li>
<li>Token 切分器（按照语言模型的限制来切分）</li>
</ol>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/data_connection/document_transformers/">[LangChain] DocumentTransform - Text Splitters</a></p>
<h2 id="文本嵌入模型-Text-Embedding-Models"><a href="#文本嵌入模型-Text-Embedding-Models" class="headerlink" title="文本嵌入模型 Text Embedding Models"></a>文本嵌入模型 Text Embedding Models</h2><p>文本嵌入模型是输入一段文本并输出其的矢量表示。这意味着我们可以在向量空间中思考文本，并执行语义搜索之类的操作，在向量空间中查找最相似的文本片段。</p>
<p>LangChain 中的 Embeddings 类是设计用于与文本嵌入模型交互的类。有很多嵌入模型提供者（OpenAI、Cohere、Hugging Face 等）——此类旨在为所有提供者提供标准接口。Embeddings 基类公开了两种方法：一种用于嵌入文档，另一种用于嵌入查询。前者采用多个文本作为输入，而后者采用单个文本。将它们作为两种单独方法的原因是，某些嵌入提供程序对文档（要搜索的）与查询（搜索查询本身）有不同的嵌入方法。</p>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/data_connection/text_embedding/">[LangChain] Text Embedding Models</a></p>
<h2 id="向量检索-Retrievers"><a href="#向量检索-Retrievers" class="headerlink" title="向量检索 Retrievers"></a>向量检索 Retrievers</h2><p>Retriever 是非结构化数据查询的通用接口，且不包含存储文档。</p>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/data_connection/retrievers/">[LangChain] Retrievers</a></p>
<h2 id="向量存储-Vector-Stores"><a href="#向量存储-Vector-Stores" class="headerlink" title="向量存储 Vector Stores"></a>向量存储 Vector Stores</h2><p>向量存储 Vector Stores 是 向量检索 Retrievers 的扩展。在存储非结构化数据，通常会先 embedding 数据并存储生成的向量 vector。在查询时，先 embedding 非结构化查询文本并检索与嵌入查询“最相似”的嵌入向量。</p>
<p>多种实现详见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/data_connection/vectorstores/">[LangChain] Vector Stores</a></p>
<h1 id="链-Chains"><a href="#链-Chains" class="headerlink" title="链 Chains"></a>链 Chains</h1><p>复杂的程序需要将 LLMs 链接编排达到最大化的能力。例如：我们可以通过创建一个 Chain 获取用户的输入，并使用 PromptTemplate 结构化，然后将转化后的内容传递给 LLM。我们能构建更多复杂的 Chain 并通过一个 Chain 串联，或者与其他组件进行串联。</p>
<h2 id="Chain"><a href="#Chain" class="headerlink" title="Chain"></a>Chain</h2><p>所有链的基类。</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>参数</th>
<th>解释</th>
</tr>
</thead>
<tbody>
<tr>
<td>verbose</td>
<td>设置为 True 时，详细输出每个链的输入及输出</td>
</tr>
<tr>
<td>memory</td>
<td>通过定义 memory 可以实现跨链调用持久化数据，用法详见 《内存 Memory》</td>
</tr>
<tr>
<td>callbacks</td>
<td></td>
</tr>
<tr>
<td>tags</td>
</tr>
</tbody>
</table>
</div>
<h2 id="基于-Documents-的链"><a href="#基于-Documents-的链" class="headerlink" title="基于 Documents 的链"></a>基于 Documents 的链</h2><h3 id="LLM"><a href="#LLM" class="headerlink" title="LLM"></a>LLM</h3><p>LLMChain 包含 PromptTemplate 和 LLM。LLMChain 运行时会将传入的参数拼接到 PromptTemplate 上（Memory 中如果有有效的 KV 值也可以）形成 Prompt，然后将其传入 LLM 中并返回 LLM 的输出。</p>
<p>其调用方式见 <a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/chains/foundational/llm_chain">[LangChain] Chains - LLM</a></p>
<h3 id="Router"><a href="#Router" class="headerlink" title="Router"></a>Router</h3><p>Router Chain 可以帮助我们动态选择模版。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>router <span class="token keyword">import</span> MultiPromptChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> ConversationChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>llm <span class="token keyword">import</span> LLMChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate

<span class="token comment"># 1. 定义不同的模版以及对应的描述</span>
physics_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a very smart physics professor. \
You are great at answering questions about physics in a concise and easy to understand manner. \
When you don't know the answer to a question you admit that you don't know.

Here is a question:
&#123;input&#125;"""</span>


math_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""You are a very good mathematician. You are great at answering math questions. \
You are so good because you are able to break down hard problems into their component parts, \
answer the component parts, and then put them together to answer the broader question.

Here is a question:
&#123;input&#125;"""</span>

prompt_infos <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">&#123;</span>
        <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"physics"</span><span class="token punctuation">,</span>
        <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"Good for answering questions about physics"</span><span class="token punctuation">,</span>
        <span class="token string">"prompt_template"</span><span class="token punctuation">:</span> physics_template<span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
    <span class="token punctuation">&#123;</span>
        <span class="token string">"name"</span><span class="token punctuation">:</span> <span class="token string">"math"</span><span class="token punctuation">,</span>
        <span class="token string">"description"</span><span class="token punctuation">:</span> <span class="token string">"Good for answering math questions"</span><span class="token punctuation">,</span>
        <span class="token string">"prompt_template"</span><span class="token punctuation">:</span> math_template<span class="token punctuation">,</span>
    <span class="token punctuation">&#125;</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

<span class="token comment"># 2. 指定路由链的多个目的地</span>
llm <span class="token operator">=</span> OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span>

destination_chains <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span>
<span class="token keyword">for</span> p_info <span class="token keyword">in</span> prompt_infos<span class="token punctuation">:</span>
    name <span class="token operator">=</span> p_info<span class="token punctuation">[</span><span class="token string">"name"</span><span class="token punctuation">]</span>
    prompt_template <span class="token operator">=</span> p_info<span class="token punctuation">[</span><span class="token string">"prompt_template"</span><span class="token punctuation">]</span>
    prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>template<span class="token operator">=</span>prompt_template<span class="token punctuation">,</span> input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    chain <span class="token operator">=</span> LLMChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> prompt<span class="token operator">=</span>prompt<span class="token punctuation">)</span>
    destination_chains<span class="token punctuation">[</span>name<span class="token punctuation">]</span> <span class="token operator">=</span> chain
default_chain <span class="token operator">=</span> ConversationChain<span class="token punctuation">(</span>llm<span class="token operator">=</span>llm<span class="token punctuation">,</span> output_key<span class="token operator">=</span><span class="token string">"text"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="LLMRouterChain"><a href="#LLMRouterChain" class="headerlink" title="LLMRouterChain"></a>LLMRouterChain</h4><p>LLM Router 通过 LLM 来决定目标链。</p>
<p>一般通过如下步骤执行：</p>
<ol>
<li>定义不同的模版以及对应的描述</li>
<li>指定路由链的目的地</li>
<li>使用LLM选择路由的目的地</li>
<li>具体执行路由</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>router<span class="token punctuation">.</span>llm_router <span class="token keyword">import</span> LLMRouterChain<span class="token punctuation">,</span> RouterOutputParser
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>router<span class="token punctuation">.</span>multi_prompt_prompt <span class="token keyword">import</span> MULTI_PROMPT_ROUTER_TEMPLATE

<span class="token comment"># 3. 使用LLM选择路由的目的地</span>
destinations <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string-interpolation"><span class="token string">f"</span><span class="token interpolation"><span class="token punctuation">&#123;</span>p<span class="token punctuation">[</span><span class="token string">'name'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">: </span><span class="token interpolation"><span class="token punctuation">&#123;</span>p<span class="token punctuation">[</span><span class="token string">'description'</span><span class="token punctuation">]</span><span class="token punctuation">&#125;</span></span><span class="token string">"</span></span> <span class="token keyword">for</span> p <span class="token keyword">in</span> prompt_infos<span class="token punctuation">]</span>
destinations_str <span class="token operator">=</span> <span class="token string">"\n"</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>destinations<span class="token punctuation">)</span>
router_template <span class="token operator">=</span> MULTI_PROMPT_ROUTER_TEMPLATE<span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>destinations<span class="token operator">=</span>destinations_str<span class="token punctuation">)</span>
router_prompt <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span>router_template<span class="token punctuation">,</span>
    input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span><span class="token punctuation">,</span>
    output_parser<span class="token operator">=</span>RouterOutputParser<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>
router_chain <span class="token operator">=</span> LLMRouterChain<span class="token punctuation">.</span>from_llm<span class="token punctuation">(</span>llm<span class="token punctuation">,</span> router_prompt<span class="token punctuation">)</span>

<span class="token comment"># 4. 具体执行路由</span>
chain <span class="token operator">=</span> MultiPromptChain<span class="token punctuation">(</span>
    router_chain<span class="token operator">=</span>router_chain<span class="token punctuation">,</span>
    destination_chains<span class="token operator">=</span>destination_chains<span class="token punctuation">,</span>
    default_chain<span class="token operator">=</span>default_chain<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span>

<span class="token keyword">print</span><span class="token punctuation">(</span>chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"What is black body radiation?"</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h4 id="EmbeddingRouterChain"><a href="#EmbeddingRouterChain" class="headerlink" title="EmbeddingRouterChain"></a>EmbeddingRouterChain</h4><p>Embedding Router 使用嵌入和相似度来决定目标链。</p>
<p>一般通过如下步骤执行：</p>
<ol>
<li>定义不同的模版以及对应的描述</li>
<li>指定路由链的目的地</li>
<li>根据 Embedding 的相似度比较决定目标链</li>
<li>具体执行路由</li>
</ol>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains<span class="token punctuation">.</span>router<span class="token punctuation">.</span>embedding_router <span class="token keyword">import</span> EmbeddingRouterChain
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings <span class="token keyword">import</span> CohereEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

names_and_descriptions <span class="token operator">=</span> <span class="token punctuation">[</span>
    <span class="token punctuation">(</span><span class="token string">"physics"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"for questions about physics"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
    <span class="token punctuation">(</span><span class="token string">"math"</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token string">"for questions about math"</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
<span class="token punctuation">]</span>

router_chain <span class="token operator">=</span> EmbeddingRouterChain<span class="token punctuation">.</span>from_names_and_descriptions<span class="token punctuation">(</span>
    names_and_descriptions<span class="token punctuation">,</span> Chroma<span class="token punctuation">,</span> CohereEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> routing_keys<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"input"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

chain <span class="token operator">=</span> MultiPromptChain<span class="token punctuation">(</span>
    router_chain<span class="token operator">=</span>router_chain<span class="token punctuation">,</span>
    destination_chains<span class="token operator">=</span>destination_chains<span class="token punctuation">,</span>
    default_chain<span class="token operator">=</span>default_chain<span class="token punctuation">,</span>
    verbose<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span>
<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Sequential"><a href="#Sequential" class="headerlink" title="Sequential"></a>Sequential</h3><p>Sequential 用于链式调用 LLM，且将上一个模型的输出当作下一个模型的输入。</p>
<p>Sequential 链有两种类型：</p>
<ul>
<li><code>SimpleSequentialChain</code>：顺序链的最简单形式，其中每个步骤都有一个单一的输入/输出，并且一个步骤的输出是下一步的输入。</li>
<li><code>SequentialChain</code>：更通用的顺序链形式，允许多个输入/输出。</li>
</ul>
<h3 id="Transformation"><a href="#Transformation" class="headerlink" title="Transformation"></a>Transformation</h3><p>Transformation 是用于通用转换的链，input_variables 用于指定输入的变量， output_variables 用于指定输出的变量，transform 指定转换的函数。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain <span class="token keyword">import</span> TransformChain

TransformChain<span class="token punctuation">(</span>input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"text"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> output_variables<span class="token punctuation">[</span><span class="token string">"entities"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>func<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span></span></code></pre>
<h2 id="链的工作模式"><a href="#链的工作模式" class="headerlink" title="链的工作模式"></a>链的工作模式</h2><p>全部的链实现了一个通用接口：</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">BaseCombineDocumentsChain</span><span class="token punctuation">(</span>Chain<span class="token punctuation">,</span> ABC<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token triple-quoted-string string">"""Base interface for chains combining documents."""</span>

    <span class="token decorator annotation punctuation">@abstractmethod</span>
    <span class="token keyword">def</span> <span class="token function">combine_docs</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> docs<span class="token punctuation">:</span> List<span class="token punctuation">[</span>Document<span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token operator">**</span>kwargs<span class="token punctuation">:</span> Any<span class="token punctuation">)</span> <span class="token operator">-</span><span class="token operator">></span> Tuple<span class="token punctuation">[</span><span class="token builtin">str</span><span class="token punctuation">,</span> <span class="token builtin">dict</span><span class="token punctuation">]</span><span class="token punctuation">:</span>
        <span class="token triple-quoted-string string">"""Combine documents into a single string."""</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<h3 id="Stuff"><a href="#Stuff" class="headerlink" title="Stuff"></a>Stuff</h3><p>Stuff Documents Chain 也就是填充文档链，他将问题和相关的内容全部填充在 PromptTemplate 中，并且将 Prompt 传递给 LLM。</p>
<blockquote>
<p>适用于小文档并且大多数调用只传少数文档。</p>
</blockquote>
<p><img src="/images/LLM/文档链stuff.jpg" alt=""></p>
<h3 id="Refine"><a href="#Refine" class="headerlink" title="Refine"></a>Refine</h3><p>Refine Document Chain 通过循环输入文档并且迭代更新其结果。对于每个文档，它将所有非文档输入、当前文档和最新的中间答案传递给 LLM 链以获得新答案。</p>
<p>由于 Refine 链一次仅将单个文档传递给 LLM，因此它非常适合需要分析的文档数量多于模型上下文的任务。明显的权衡是，该链将比 Stuff 文档链进行更多的 LLM 调用。还有一些任务很难迭代完成。例如，当文档频繁相互交叉引用或一项任务需要来自许多文档的详细信息时，Refine 链可能会表现不佳。</p>
<p><img src="/images/LLM/文档链refine.jpg" alt=""></p>
<h3 id="Map-Reduce"><a href="#Map-Reduce" class="headerlink" title="Map Reduce"></a>Map Reduce</h3><p>MapReduce Documents Chain 首先将 LLM 链单独应用于每个文档（Map 步骤），将链输出视为新文档。然后，它将所有新文档传递到单独的组合文档链以获得单个输出（Reduce 步骤）。它可以选择首先压缩或折叠映射的文档，以确保它们适合组合文档链（这通常会将它们传递给 LLM）。如有必要，该压缩步骤会递归执行。</p>
<p><img src="/images/LLM/文档链mapreduce.jpeg" alt=""></p>
<h3 id="Map-Re-rank"><a href="#Map-Re-rank" class="headerlink" title="Map Re-rank"></a>Map Re-rank</h3><p>Map Re-rank Documents Chain 会对每个文档运行初始 Prompt，这不仅会尝试完成任务，还会对其答案的确定性进行评分，并返回得分最高的响应。</p>
<p><img src="/images/LLM/文档链maprerank.jpeg" alt=""></p>
<h2 id="流行用法"><a href="#流行用法" class="headerlink" title="流行用法"></a>流行用法</h2><h3 id="API-Chains"><a href="#API-Chains" class="headerlink" title="API Chains"></a>API Chains</h3><p>API 链主要是使用 LLM 与 API 进行交互。</p>
<h3 id="Retrieval-QA"><a href="#Retrieval-QA" class="headerlink" title="Retrieval QA"></a>Retrieval QA</h3><p>Retrieval QA 是构建在索引上的问答模式。他可以设置不同的工作模式：Stuff、Refine、Map Reduce、Map Re-rank。</p>
<p><strong>默认调用</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> RetrievalQA
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>document_loaders <span class="token keyword">import</span> TextLoader
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>embeddings<span class="token punctuation">.</span>openai <span class="token keyword">import</span> OpenAIEmbeddings
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>llms <span class="token keyword">import</span> OpenAI
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>text_splitter <span class="token keyword">import</span> CharacterTextSplitter
<span class="token keyword">from</span> langchain<span class="token punctuation">.</span>vectorstores <span class="token keyword">import</span> Chroma

loader <span class="token operator">=</span> TextLoader<span class="token punctuation">(</span><span class="token string">"../../state_of_the_union.txt"</span><span class="token punctuation">)</span>
documents <span class="token operator">=</span> loader<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token punctuation">)</span>
text_splitter <span class="token operator">=</span> CharacterTextSplitter<span class="token punctuation">(</span>chunk_size<span class="token operator">=</span><span class="token number">1000</span><span class="token punctuation">,</span> chunk_overlap<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
texts <span class="token operator">=</span> text_splitter<span class="token punctuation">.</span>split_documents<span class="token punctuation">(</span>documents<span class="token punctuation">)</span>

embeddings <span class="token operator">=</span> OpenAIEmbeddings<span class="token punctuation">(</span><span class="token punctuation">)</span>
docsearch <span class="token operator">=</span> Chroma<span class="token punctuation">.</span>from_documents<span class="token punctuation">(</span>texts<span class="token punctuation">,</span> embeddings<span class="token punctuation">)</span>

qa <span class="token operator">=</span> RetrievalQA<span class="token punctuation">.</span>from_chain_type<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">,</span> retriever<span class="token operator">=</span>docsearch<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
query <span class="token operator">=</span> <span class="token string">"What did the president say about Ketanji Brown Jackson"</span>
qa<span class="token punctuation">.</span>run<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>自定义 Prompts</strong></p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>prompts <span class="token keyword">import</span> PromptTemplate
prompt_template <span class="token operator">=</span> <span class="token triple-quoted-string string">"""Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer.

&#123;context&#125;

Question: &#123;question&#125;
Answer in Italian:"""</span>
PROMPT <span class="token operator">=</span> PromptTemplate<span class="token punctuation">(</span>
    template<span class="token operator">=</span>prompt_template<span class="token punctuation">,</span> input_variables<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">"context"</span><span class="token punctuation">,</span> <span class="token string">"question"</span><span class="token punctuation">]</span>
<span class="token punctuation">)</span>

chain_type_kwargs <span class="token operator">=</span> <span class="token punctuation">&#123;</span><span class="token string">"prompt"</span><span class="token punctuation">:</span> PROMPT<span class="token punctuation">&#125;</span>
qa <span class="token operator">=</span> RetrievalQA<span class="token punctuation">.</span>from_chain_type<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">,</span> retriever<span class="token operator">=</span>docsearch<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chain_type_kwargs<span class="token operator">=</span>chain_type_kwargs<span class="token punctuation">)</span>

query <span class="token operator">=</span> <span class="token string">"What did the president say about Ketanji Brown Jackson"</span>
qa<span class="token punctuation">.</span>run<span class="token punctuation">(</span>query<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><strong>返回原文档</strong></p>
<p>支持通过配置指定参数来返回关联的原文档。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python">qa <span class="token operator">=</span> RetrievalQA<span class="token punctuation">.</span>from_chain_type<span class="token punctuation">(</span>llm<span class="token operator">=</span>OpenAI<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> chain_type<span class="token operator">=</span><span class="token string">"stuff"</span><span class="token punctuation">,</span> retriever<span class="token operator">=</span>docsearch<span class="token punctuation">.</span>as_retriever<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> return_source_documents<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span></span></code></pre>
<h3 id="Conversational-Retrieval-QA"><a href="#Conversational-Retrieval-QA" class="headerlink" title="Conversational Retrieval QA"></a>Conversational Retrieval QA</h3><p>Conversational Retrieval QA 基于 Retrieval QA 构建。</p>
<h3 id="SQL"><a href="#SQL" class="headerlink" title="SQL"></a>SQL</h3><p>使用<code>SQLDatabaseChain</code>回答有关 SQL 数据库的问题。</p>
<h3 id="Summarization"><a href="#Summarization" class="headerlink" title="Summarization"></a>Summarization</h3><p>摘要链可用于汇总多个文档。一种方法是输入多个较小的文档，将它们分为块后，并使用 MapReduceDocumentsChain 对它们进行操作。您还可以选择将进行汇总的链改为 StuffDocumentsChain 或 RefineDocumentsChain。</p>
<h3 id="Using-OpenAI-functions"><a href="#Using-OpenAI-functions" class="headerlink" title="Using OpenAI functions"></a>Using OpenAI functions</h3><p>调用 OpenAI Function API 并合并到链中。</p>
<h2 id="Additional"><a href="#Additional" class="headerlink" title="Additional"></a>Additional</h2><p><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/chains/additional/analyze_document">[LangChain] Chains - Additional</a></p>
<h2 id="LangChainHub"><a href="#LangChainHub" class="headerlink" title="LangChainHub"></a>LangChainHub</h2><p>通过 <a target="_blank" rel="noopener" href="https://github.com/hwchase17/langchain-hub">LangChainHub</a> 加载 Chains。涉及的序列化相关见<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/chains/how_to/serialization">[LangChain] Serialization</a>。</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token keyword">from</span> langchain<span class="token punctuation">.</span>chains <span class="token keyword">import</span> load_chain

chain <span class="token operator">=</span> load_chain<span class="token punctuation">(</span><span class="token string">"lc://chains/llm-math/chain.json"</span><span class="token punctuation">)</span>
chain<span class="token punctuation">.</span>run<span class="token punctuation">(</span><span class="token string">"whats 2 raised to .12"</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span></span></code></pre>
<h1 id="内存-Memory"><a href="#内存-Memory" class="headerlink" title="内存 Memory"></a>内存 Memory</h1><p>LangChain 提供两种形式的内存组件。首先，LangChain 提供了帮助实用程序来管理和操作以前的聊天消息。它们被设计为模块化且有用的，无论它们如何使用。其次，LangChain 提供了将这些实用程序整合到链中的简单方法。</p>
<h1 id="代理-Agents"><a href="#代理-Agents" class="headerlink" title="代理 Agents"></a>代理 Agents</h1><p>某些应用程序需要根据用户输入对 LLM 和其他工具进行灵活的调用。Agents 接口为此类应用程序提供了灵活性。代理可以访问一套工具，并根据用户输入确定使用哪些工具。代理可以使用多种工具，并使用一个工具的输出作为下一个工具的输入。</p>
<p>代理主要有两种类型：</p>
<ul>
<li><strong>Action agents</strong>：在每个时间步，使用所有先前动作的输出来决定下一个动作</li>
<li><strong>Plan-and-execute agents</strong>：预先决定完整的操作顺序，然后执行所有操作而不更新计划</li>
</ul>
<p>Action agents 适合小型任务，而 Plan-and-execute agents 更适合需要维护长期目标和复杂的焦点或长期运行的任务。通常，最好的方法是通过让计划和执行代理使用行动代理来执行计划，将行动代理的活力与计划和执行代理的规划能力结合起来。</p>
<p>有关代理类型的完整列表，请参阅<a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/agents/agent_types/">Agent types</a>。代理涉及的其他抽象包括：</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/agents/tools/"><strong>Tools</strong></a>：代理可以采取的操作。您为代理提供哪些工具很大程度上取决于您希望代理做什么</li>
<li><a target="_blank" rel="noopener" href="https://python.langchain.com/docs/modules/agents/toolkits/"><strong>Toolkits</strong></a>：对可在特定用例中一起使用的工具集合的包装。例如，为了让代理与 SQL 数据库交互，它可能需要一个工具来执行查询，另一个工具来检查表。</li>
</ul>
<h2 id="Action-Agents"><a href="#Action-Agents" class="headerlink" title="Action Agents"></a>Action Agents</h2><p>一个高级的 Action Agents 的执行过程以下：</p>
<ol>
<li>接收用户输入</li>
<li>决定使用哪个工具（如果有）以及工具输入</li>
<li>调用该工具并记录输出（也称为“观察”）</li>
<li>使用工具历史记录、工具输入和观察结果决定下一步</li>
<li>重复3-4，直到确定可以直接响应用户</li>
</ol>
<p>操作代理被包装在 <strong>agents executors</strong> 中，代理执行器负责调用代理，获取操作和操作输入，使用生成的输入调用操作引用的工具，获取工具的输出，然后将所有信息传回进入代理以获取它应该采取的下一步行动。</p>
<p>尽管代理可以通过多种方式构建，但它通常涉及以下组件：</p>
<ul>
<li><strong>提示模板</strong>：负责获取用户输入和之前的步骤并构建发送到语言模型的提示</li>
<li><strong>语言模型</strong>：接受使用输入和操作历史记录的提示，并决定下一步做什么</li>
<li><strong>输出解析器</strong>：获取语言模型的输出并将其解析为下一个动作或最终答案</li>
</ul>
<h2 id="Plan-and-execute-Agents"><a href="#Plan-and-execute-Agents" class="headerlink" title="Plan-and-execute Agents"></a>Plan-and-execute Agents</h2><p>一个高级的 Plan-and-execute Agents 的执行过程以下：</p>
<ol>
<li>接收用户输入</li>
<li>计划要采取的完整步骤顺序</li>
<li>按顺序执行步骤，将过去步骤的输出作为未来步骤的输入传递</li>
</ol>
<p>最典型的实现是让规划器成为语言模型，执行器成为动作代理。</p>
<h1 id="回调-Callbacks"><a href="#回调-Callbacks" class="headerlink" title="回调 Callbacks"></a>回调 Callbacks</h1><p>LangChain 提供了一个回调系统，允许您连接到 LLM 申请的各个阶段。这对于日志记录、监控、流传输和其他任务非常有用。</p>

    </div>

    
    
    

      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/LLM/" rel="tag"># LLM</a>
              <a href="/tags/LangChain/" rel="tag"># LangChain</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2023/06/26/%E6%94%AF%E4%BB%98%E7%B3%BB%E7%BB%9F-3-%E6%B8%85%E7%BB%93%E7%AE%97-3-%E8%B4%A6%E5%8A%A1%E7%B3%BB%E7%BB%9F/" rel="prev" title="架构设计 支付清结算系统 账务系统">
      <i class="fa fa-chevron-left"></i> 架构设计 支付清结算系统 账务系统
    </a></div>
      <div class="post-nav-item">
    <a href="/2023/08/07/SE-%E6%B8%85%E6%99%B0%E6%9E%B6%E6%9E%84/" rel="next" title="架构设计 清晰架构">
      架构设计 清晰架构 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%A8%A1%E5%9E%8BIO"><span class="nav-number">1.</span> <span class="nav-text">模型IO</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%8F%90%E7%A4%BA-Prompts"><span class="nav-number">1.1.</span> <span class="nav-text">提示 Prompts</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Prompt-Templates"><span class="nav-number">1.1.1.</span> <span class="nav-text">Prompt Templates</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chat-Prompt-Template"><span class="nav-number">1.1.2.</span> <span class="nav-text">Chat Prompt Template</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-Language-Models"><span class="nav-number">1.2.</span> <span class="nav-text">语言模型 Language Models</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LLMS"><span class="nav-number">1.2.1.</span> <span class="nav-text">LLMS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Chat-Models"><span class="nav-number">1.2.2.</span> <span class="nav-text">Chat Models</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Caching"><span class="nav-number">1.2.2.1.</span> <span class="nav-text">Caching</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Streaming"><span class="nav-number">1.2.2.2.</span> <span class="nav-text">Streaming</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E8%BE%93%E5%87%BA%E5%88%86%E6%9E%90%E5%99%A8-Output-Parser"><span class="nav-number">1.3.</span> <span class="nav-text">输出分析器 Output Parser</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E6%95%B0%E6%8D%AE%E8%BF%9E%E6%8E%A5-Data-Connection"><span class="nav-number">2.</span> <span class="nav-text">数据连接 Data Connection</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%A1%A3%E5%8A%A0%E8%BD%BD%E5%99%A8-Document-Loaders"><span class="nav-number">2.1.</span> <span class="nav-text">文档加载器 Document Loaders</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%A1%A3%E8%BD%AC%E6%8D%A2%E5%99%A8-Document-Transformers"><span class="nav-number">2.2.</span> <span class="nav-text">文档转换器 Document Transformers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%96%87%E6%9C%AC%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B-Text-Embedding-Models"><span class="nav-number">2.3.</span> <span class="nav-text">文本嵌入模型 Text Embedding Models</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2-Retrievers"><span class="nav-number">2.4.</span> <span class="nav-text">向量检索 Retrievers</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%AD%98%E5%82%A8-Vector-Stores"><span class="nav-number">2.5.</span> <span class="nav-text">向量存储 Vector Stores</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E9%93%BE-Chains"><span class="nav-number">3.</span> <span class="nav-text">链 Chains</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Chain"><span class="nav-number">3.1.</span> <span class="nav-text">Chain</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%9F%BA%E4%BA%8E-Documents-%E7%9A%84%E9%93%BE"><span class="nav-number">3.2.</span> <span class="nav-text">基于 Documents 的链</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#LLM"><span class="nav-number">3.2.1.</span> <span class="nav-text">LLM</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Router"><span class="nav-number">3.2.2.</span> <span class="nav-text">Router</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#LLMRouterChain"><span class="nav-number">3.2.2.1.</span> <span class="nav-text">LLMRouterChain</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#EmbeddingRouterChain"><span class="nav-number">3.2.2.2.</span> <span class="nav-text">EmbeddingRouterChain</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sequential"><span class="nav-number">3.2.3.</span> <span class="nav-text">Sequential</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Transformation"><span class="nav-number">3.2.4.</span> <span class="nav-text">Transformation</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E9%93%BE%E7%9A%84%E5%B7%A5%E4%BD%9C%E6%A8%A1%E5%BC%8F"><span class="nav-number">3.3.</span> <span class="nav-text">链的工作模式</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Stuff"><span class="nav-number">3.3.1.</span> <span class="nav-text">Stuff</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Refine"><span class="nav-number">3.3.2.</span> <span class="nav-text">Refine</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-Reduce"><span class="nav-number">3.3.3.</span> <span class="nav-text">Map Reduce</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Map-Re-rank"><span class="nav-number">3.3.4.</span> <span class="nav-text">Map Re-rank</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B5%81%E8%A1%8C%E7%94%A8%E6%B3%95"><span class="nav-number">3.4.</span> <span class="nav-text">流行用法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#API-Chains"><span class="nav-number">3.4.1.</span> <span class="nav-text">API Chains</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Retrieval-QA"><span class="nav-number">3.4.2.</span> <span class="nav-text">Retrieval QA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Conversational-Retrieval-QA"><span class="nav-number">3.4.3.</span> <span class="nav-text">Conversational Retrieval QA</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SQL"><span class="nav-number">3.4.4.</span> <span class="nav-text">SQL</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Summarization"><span class="nav-number">3.4.5.</span> <span class="nav-text">Summarization</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-OpenAI-functions"><span class="nav-number">3.4.6.</span> <span class="nav-text">Using OpenAI functions</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Additional"><span class="nav-number">3.5.</span> <span class="nav-text">Additional</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LangChainHub"><span class="nav-number">3.6.</span> <span class="nav-text">LangChainHub</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%86%85%E5%AD%98-Memory"><span class="nav-number">4.</span> <span class="nav-text">内存 Memory</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E4%BB%A3%E7%90%86-Agents"><span class="nav-number">5.</span> <span class="nav-text">代理 Agents</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Action-Agents"><span class="nav-number">5.1.</span> <span class="nav-text">Action Agents</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Plan-and-execute-Agents"><span class="nav-number">5.2.</span> <span class="nav-text">Plan-and-execute Agents</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E5%9B%9E%E8%B0%83-Callbacks"><span class="nav-number">6.</span> <span class="nav-text">回调 Callbacks</span></a></li></ol></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Wang Zihao</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">163</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
            <a href="/categories/">
          
        <span class="site-state-item-count">31</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
            <a href="/tags/">
          
        <span class="site-state-item-count">311</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>



      </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2023</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Wang Zihao</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.org/" class="theme-link" rel="noopener" target="_blank">NexT.Gemini</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

  

</body>
</html>
